{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommendations task\n",
    "Here the task is to create a model that recommends movies. At first to explore the data and and build a simpler model.\n",
    "\n",
    "Thereafter to describe and implement a usual technique for recommendations. Suggested techniqeus are either content-filtering or collaborative-filtering. As collaborative-filtering can offer more diverse recommendations, and also suggest movies that the user might not otherwise have found, this technique was chosen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After preliminary opening of the movielens archive, some limitations were immediately obvious: \n",
    "- To ignore tags.csv, links.csv\n",
    "- From movies.csv use genres column, in ratings.csv all columns.\n",
    "\n",
    "A random subset needs to be selected to perform the training as 25,000,000 ratings are quite a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "movie_df = pd.read_csv('moviedata/movies.csv', header=0)\n",
    "rating_df = pd.read_csv('moviedata/ratings.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index of rating_df\n",
    "rating_df = rating_df.reset_index(drop=True)\n",
    "\n",
    "# Perform the reindexing operation\n",
    "rating_df['title'] = rating_df['movieId'].map(movie_df.set_index('movieId')['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1147880044</td>\n",
       "      <td>Pulp Fiction (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>306</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1147868817</td>\n",
       "      <td>Three Colors: Red (Trois couleurs: Rouge) (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1147868828</td>\n",
       "      <td>Three Colors: Blue (Trois couleurs: Bleu) (1993)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>665</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1147878820</td>\n",
       "      <td>Underground (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>899</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1147868510</td>\n",
       "      <td>Singin' in the Rain (1952)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp  \\\n",
       "0       1      296     5.0  1147880044   \n",
       "1       1      306     3.5  1147868817   \n",
       "2       1      307     5.0  1147868828   \n",
       "3       1      665     5.0  1147878820   \n",
       "4       1      899     3.5  1147868510   \n",
       "\n",
       "                                              title  \n",
       "0                               Pulp Fiction (1994)  \n",
       "1  Three Colors: Red (Trois couleurs: Rouge) (1994)  \n",
       "2  Three Colors: Blue (Trois couleurs: Bleu) (1993)  \n",
       "3                                Underground (1995)  \n",
       "4                        Singin' in the Rain (1952)  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58958"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_df['title'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a more reasonably sized model, 1M rows will be sampled out of the 25M. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 5)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smaller_df = rating_df.sample(n=1000000, random_state=1)\n",
    "smaller_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how many unique movies are in the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23166"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smaller_df['title'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how many unique movies with 5 star ratings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title\n",
       "Shawshank Redemption, The (1994)             1617\n",
       "Pulp Fiction (1994)                          1282\n",
       "Schindler's List (1993)                      1072\n",
       "Star Wars: Episode IV - A New Hope (1977)    1061\n",
       "Forrest Gump (1994)                          1021\n",
       "                                             ... \n",
       "Another Cinderella Story (2008)                 1\n",
       "D.C.H. (Dil Chahta Hai) (2001)                  1\n",
       "Peacemaker, The (1997)                          1\n",
       "Prison Break: The Final Break (2009)            1\n",
       "Biutiful (2010)                                 1\n",
       "Name: count, Length: 8600, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smaller_df[(smaller_df['rating'] == 5)]['title'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing a model\n",
    "\n",
    "For the second task I choose the second option: to implement a recommendation model based on either Content Filtering or Collaborative Filtering. To get an overview of the difference between the models, I asked ChatGPT. The comparison shows that Collaborative Filtering probably is the best choice for this domain, which is also what I was thinking after reading up on the two models on Wikipedia.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChatGPT4: Here's a table that compares Content Filtering and Collaborative Filtering across several dimensions:\n",
    "\n",
    "| Feature                         | Content Filtering                                   | Collaborative Filtering                                      |\n",
    "|---------------------------------|-----------------------------------------------------|--------------------------------------------------------------|\n",
    "| **Data Required**               | Item features (e.g., genre, author)                  | User-item interactions (e.g., ratings, views)                |\n",
    "| **Recommendation Basis**        | Similarity between item features and user preferences| Similarity between users or items based on user interactions |\n",
    "| **Advantages**                  | - Privacy-friendly <br> - Can recommend new items <br> - Transparent reasoning      | - Diverse recommendations <br> - Can discover serendipitous items <br> - Effective without item metadata            |\n",
    "| **Limitations**                 | - Limited by item features <br> - Risk of over-specialization <br> - Cold start problem for new users | - Cold start problem for new users/items <br> - Requires large amounts of data <br> - Scalability issues            |\n",
    "| **Application Examples**        | - E-commerce product recommendations <br> - Online libraries and content platforms | - Movie, music, and book recommendations <br> - E-commerce and social networking sites                             |\n",
    "| **User/Item Newness Handling**  | Can handle new items if item features are available  | Struggles with new users and items due to lack of interaction data                                                 |\n",
    "| **Diversity of Recommendations**| May recommend items too similar to user's past likes | Generally offers more diverse recommendations                |\n",
    "| **Requirement for Metadata**    | High (needs detailed item features)                   | Low (relies on user behavior rather than item specifics)      |\n",
    "\n",
    "Collaborative Filtering was chosen, thus genres and tags are not necessary features for this implementation. ChatGPT suggests to use Singular Value Decomposition (SVD) to handle the sparse data and the large number of rows to implement a specific Collaborative Filtering method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory\n",
    "\n",
    "Singular Value Decomposition, or SVD, is a powerful technique that breaks down a matrix $A$ into three distinct matrices: $U$, $\\Sigma$, and $V^{T}$. Here's how it goes:\n",
    "\n",
    "- Imagine $A$ as a grid where rows represent users and columns represent items, filled with ratings users have given to items.\n",
    "- $U$ is a matrix where each column is a \"user feature vector,\" representing hidden characteristics of users.\n",
    "- $\\Sigma$ is a diagonal matrix whose entries are singular values. These values rank the importance of each latent feature, from most to least impactful.\n",
    "- $V^{T}$, the transpose of $V$, contains \"item feature vectors\" in its columns, showing hidden characteristics of items.\n",
    "\n",
    "The magic formula looks like this: $A = U \\Sigma V^{T}$.\n",
    "\n",
    "By breaking down $A$ into these components, we can uncover hidden patterns in how users rate items. It's all about finding out what common tastes or preferences (represented by the latent features in $U$ and $V$) users share.\n",
    "\n",
    "The singular values in $\\Sigma$ tell us how significant each hidden feature is. By keeping only the top few features (the highest values in $\\Sigma$), we can simplify the complex world of user-item ratings into something more manageable, yet still incredibly insightful for making recommendations.\n",
    "\n",
    "This process, in essence, allows us to predict how a user might rate items they haven't encountered yet, based on the latent features. It's a cornerstone for building recommendation systems that feel almost psychic in their ability to guess what users will like.\n",
    "\n",
    "## Implementing the model\n",
    "The basis for the Collaborative Filtering using SVD is "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it was not possible to install scikit surprise using pip, an environment was created using conda, where the required packages were installed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9151  0.9138  0.9178  0.9170  0.9181  0.9164  0.0017  \n",
      "MAE (testset)     0.7044  0.7032  0.7058  0.7058  0.7063  0.7051  0.0011  \n",
      "Fit time          17.07   17.96   17.76   15.08   13.87   16.35   1.60    \n",
      "Test time         3.92    4.09    4.53    2.72    2.72    3.60    0.74    \n"
     ]
    }
   ],
   "source": [
    "from surprise import SVD, Dataset, Reader\n",
    "from surprise.model_selection import cross_validate, train_test_split\n",
    "from surprise import accuracy\n",
    "\n",
    "# Load the dataset into Surprise's format. As is was so fast, we could use the full dataset \n",
    "# model.fit() on the full dataset runs in just under 14 minutes on my 8 year old laptop\n",
    "# But due to the size of the pickle file, the smaller dataset of 1M rows will be used.\n",
    "\n",
    "reader = Reader(rating_scale=(min(smaller_df['rating']), max(smaller_df['rating'])))\n",
    "data = Dataset.load_from_df(smaller_df[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "model = SVD()\n",
    "\n",
    "# Perform 5-fold cross-validation to check results\n",
    "results = cross_validate(model, data, measures=['RMSE', 'MAE'], cv=5, verbose=True, n_jobs=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9159\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and test sets\n",
    "trainset, testset = train_test_split(data, test_size=0.2)\n",
    "\n",
    "# Train the model on the training set\n",
    "model.fit(trainset)\n",
    "\n",
    "# Predict ratings for the test set\n",
    "predictions = model.test(testset)\n",
    "\n",
    "# Evaluate the predictions\n",
    "rmse = accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks very good. RMSE on the testset consistently at 0.92.\n",
    "### Now to input some Favourite movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your favorite movies (press enter to finish):\n",
      "Found: Emil i Lönneberga (1971) with ID: 51354\n",
      "Your favorite movie IDs: [51354]\n"
     ]
    }
   ],
   "source": [
    "# User input process\n",
    "user_favorites_titles = []\n",
    "print(\"Enter your favorite movies (press enter to finish):\")\n",
    "while True:\n",
    "    title_input = input()\n",
    "    if title_input == \"\":\n",
    "        break\n",
    "    user_favorites_titles.append(title_input)\n",
    "\n",
    "# Find matching movie IDs\n",
    "favorite_movie_ids = []\n",
    "\n",
    "for user_title in user_favorites_titles:\n",
    "    # Using .str.contains to find matches; case-insensitive\n",
    "    matches = movie_df[movie_df['title'].str.contains(user_title, case=False, na=False)]\n",
    "    if not matches.empty:\n",
    "        for _, row in matches.iterrows():\n",
    "            favorite_movie_ids.append(row['movieId'])\n",
    "            print(f\"Found: {row['title']} with ID: {row['movieId']}\")\n",
    "    else:\n",
    "        print(f\"No matches found for: {user_title}\")\n",
    "\n",
    "print(\"Your favorite movie IDs:\", favorite_movie_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 movie recommendations for you:\n",
      "=====================================\n",
      "1) Planet Earth II (2016), Predicted Rating: 4.6\n",
      "2) Planet Earth (2006), Predicted Rating: 4.5\n",
      "3) Children of Paradise (Les enfants du paradis) (1945), Predicted Rating: 4.5\n",
      "4) Lady Eve, The (1941), Predicted Rating: 4.4\n",
      "5) Band of Brothers (2001), Predicted Rating: 4.4\n",
      "6) Shawshank Redemption, The (1994), Predicted Rating: 4.4\n",
      "7) Jetée, La (1962), Predicted Rating: 4.4\n",
      "8) Godfather, The (1972), Predicted Rating: 4.4\n",
      "9) Mulholland Dr. (1999), Predicted Rating: 4.4\n",
      "10) George Carlin: Life Is Worth Losing (2005), Predicted Rating: 4.4\n",
      "\n",
      "Top 10 movie recommendations for you to avoid:\n",
      "##############################################\n",
      "10) Pokémon 3: The Movie (2001), Predicted Rating: 1.9\n",
      "9) Norbit (2007), Predicted Rating: 1.9\n",
      "8) Pokemon 4 Ever (a.k.a. Pokémon 4: The Movie) (2002), Predicted Rating: 1.9\n",
      "7) Kazaam (1996), Predicted Rating: 1.9\n",
      "6) Problem Child 2 (1991), Predicted Rating: 1.8\n",
      "5) From Justin to Kelly (2003), Predicted Rating: 1.8\n",
      "4) Glitter (2001), Predicted Rating: 1.7\n",
      "3) Battlefield Earth (2000), Predicted Rating: 1.7\n",
      "2) Dumb and Dumberer: When Harry Met Lloyd (2003), Predicted Rating: 1.7\n",
      "1) Gigli (2003), Predicted Rating: 1.6\n"
     ]
    }
   ],
   "source": [
    "# New user details\n",
    "new_user_id = 'new_user'  \n",
    "\n",
    "# Get the list of all movies in the dataset\n",
    "all_movie_ids = set(smaller_df['movieId'].unique())\n",
    "\n",
    "# Exclude movies that the new user has already rated (their top 3 favorites in this case)\n",
    "movies_to_predict = list(all_movie_ids - set(favorite_movie_ids))\n",
    "\n",
    "# Create a list of tuples in the form of (new_user_id, movieId, actual_rating)\n",
    "# Since we don't have actual ratings for these (new user), we can use a dummy rating value\n",
    "testset = [[new_user_id, movie_id, 5.] for movie_id in movies_to_predict]  # Dummy rating of 5\n",
    "\n",
    "# Predict ratings for all movies the new user hasn't rated\n",
    "predictions = model.test(testset)\n",
    "\n",
    "# Convert predictions to a list of (movieId, predicted_rating) tuples\n",
    "predicted_ratings = [(pred.iid, pred.est) for pred in predictions]\n",
    "\n",
    "# Sort the predictions by estimated rating in descending order\n",
    "predicted_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Get the top 10 recommendations\n",
    "top_recommendations = predicted_ratings[:10]\n",
    "\n",
    "print(\"Top 10 movie recommendations for you:\")\n",
    "print(\"=====================================\")\n",
    "i=1\n",
    "for movie_id, rating in top_recommendations:\n",
    "    movie_name = movie_df.loc[movie_df['movieId'] == movie_id, 'title'].values[0]\n",
    "    print(f\"{i}) {movie_name}, Predicted Rating: {rating:.1f}\")\n",
    "    i += 1\n",
    "\n",
    "# Get the top 10 movies to stay away from\n",
    "bottom_recommendations = predicted_ratings[-10:]\n",
    "\n",
    "i=10\n",
    "print(\"\\nTop 10 movie recommendations for you to avoid:\")\n",
    "print(\"##############################################\")\n",
    "for movie_id, rating in bottom_recommendations:\n",
    "    movie_name = movie_df.loc[movie_df['movieId'] == movie_id, 'title'].values[0]\n",
    "    print(f\"{i}) {movie_name}, Predicted Rating: {rating:.1f}\")\n",
    "    i -= 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./save/SVD_movie_model_1M.pkl']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "dump(model, './save/SVD_movie_model_1M.pkl', compress=5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
